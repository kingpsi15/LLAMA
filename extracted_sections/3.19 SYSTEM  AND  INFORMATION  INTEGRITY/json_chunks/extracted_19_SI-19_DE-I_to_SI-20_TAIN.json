{
  "subheading": "SI-19 DE-IDENTIFICATION",
  "start_text": "SI-19 DE-IDENTIFICATION b\nrControl:\na.Removethe fo",
  "content": "SI-19 DE-IDENTIFICATION b\nrControl:\na.Removethe following elements of personally identifiable information from datasets:  f\nhAssignment: organization-defined elements of personally identifiable information[]; and\neAssignment: organization-defined frequencyb.Evaluate [] for effectiveness of de-identification.\nmDiscussion:  De-identification is the general term for the process of removing the association\nhbetween a set of identifying data and the data subject. Many datasets contain information about\nindividuals that can be used to distinguish or trace an individual\u2019s identity, such as name, social s\n/security number, date and place of birth, mother\u2019s maiden name, or biometric records. Datasets d\nimay also contain other information that is linked or linkable to an individual, such as medical, .\ngeducational, financial, and employment information. Personally identifiable information is\n0removed from datasets by trained individuals when such information is not (or no longer)\nnecessary to satisfy the requirements envisioned for the data. For example, if the dataset is only 0\n8used to produce aggregate statistics, the identifiers that are not needed for producing those\nIstatistics are removed. Removing identifiers improves privacy protection since information that is\nOrganizations may be subject to removed cannot be inadvertently disclosed or improperly used..\nspecific de-identification definitions or methods under applicable laws, regulations, or policies.\n0Re-identification is a residual risk with de-identified data. Re-identification attacks can vary,\nincluding combining new datasets or other improvements in data analytics. Maintaining 5\nawareness of potential attacks and evaluating for the effectiveness of the de-identification over 5\ntime support the management of this residual risk.\nRelated Controls:  MP-6, PM-22, PM-23, PM-24, RA-2, SI-12.\nControl Enhancements:\n-| (1) DEIDENTIFICATION  COLLECTION\nDe-identify the dataset upon collection by not collectingpersonally identifiable\ninformation.\nDiscussion:  If a data source contains personally identifiable information but the information\nwill not be used, the dataset can be de-identified when it is created by not collecting the\nCHAPTER THREE   PAGE 358\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\ndata elements that contain the personally identifiable information. For example, if an\norganization does not intend to use the social security number of an applicant, then\napplication forms do not ask for a social security number.\nRelated Controls:  None.\n-| (2) DEIDENTIFICATION  ARCHIVING\nProhibit archiving of personally identifiable information elements if those elements in a\ndataset will not be needed after the dataset is archived.\nDiscussion:  Datasets can be archived for many reasons. The envisioned purposes for the\narchived dataset are specified, and if personally identifiable information elements are not\nrequired, the elements are not archived. For example, social security numbers may have\nbeen collected for record linkage, but the archived dataset may include the required\nelements from the linked records. In this case, it is not necessary to archive the social\nsecurity numbers. is\nuRelated Controls:  None.\na-| (3) DEIDENTIFICATION  RELEASE\nn Removepersonally identifiable information elements from a dataset prior to its release if\nthose elements in the dataset do not need to be part of the data release.\nDiscussion:  Prior to releasing a dataset, a data custodian considers the intended uses of the i\nbdataset and determines if it is necessary to release personally identifiable information. If the\npersonally identifiable information is not necessary, the information can be removed using f\nede-identification techniques.\nRelated Controls:  None. c\n-|,,,,g(4) DEIDENTIFICATION  REMOVAL MASKING ENCRYPTION HASHING OR REPLACEMENT OF DIRECT\nf IDENTIFIERSr\nRemove, mask, encrypt, hash, or replace direct identifiers in a dataset. :\ntDiscussion:  There are many possible processes for removing direct identifiers from a p\n:dataset. Columns in a dataset that contain a direct identifier can be removed. In masking, /\nothe direct identifier is transformed into a repeating character, such as XXXXXX or 999999.\nIdentifiers can be encrypted or hashed so that the linked records remain linked. In the case r\n1of encryption or hashing, algorithms are employed that require the use of a key, including\n6the Advanced Encryption Standard or a Hash-based Message Authentication Code.\nImplementations may use the same key for all identifiers or use a different key for each\nidentifier. Using a different key for each identifier provides a higher degree of security and\nprivacy. Identifiers can alternatively be replaced with a keyword, including transforming T\n\u201cGeorge Washington\u201d to \u201cPATIENT\u201d or replacing it with a surrogate value, such as\n8transforming \u201cGeorge Washington\u201d to \u201cAbraham Polk.\u201d\n-Related Controls:  SC-12, SC-13. 5\n-| (5)  DEIDENTIFICATION  STATISTICAL DISCLOSURE CONTROL\nManipulate numerical data, contingency tables, and statistical findings so that no\nindividual or organization is identifiable in the results of the analysis.\nDiscussion:  Many types of statistical analyses can result in the disclosure of information\nabout individuals even if only summary information is provided. For example, if a school that\npublishes a monthly table with the number of minority students enrolled, reports that it has\n10-19 such students in January, and subsequently reports that it has 20-29 such students in\nMarch, then it can be inferred that the student who enrolled in February was a minority.\nRelated Controls:  None.\nCHAPTER THREE   PAGE 359\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\n-| (6) DEIDENTIFICATION  DIFFERENTIAL PRIVACY\nPrevent disclosure of personally identifiable information by adding non-deterministic\nnoise to the results of mathematical operations before the results are reported.\nDiscussion:  The mathematical definition for differential privacy holds that the result of a\ndataset analysis should be approximately the same before and after the addition or removal\nof a single data record (which is assumed to be the data from a single individual). In its most\nbasic form, differential privacy applies only to online query systems. However, it can also be\nused to produce machine-learning statistical classifiers and synthetic data. Differential\nprivacy comes at the cost of decreased accuracy of results, forcing organizations to quantify\nthe trade-off between privacy protection and the overall accuracy, usefulness, and utility of\nthe de-identified dataset. Non-deterministic noise can include adding small, random values\nto the results of mathematical operations in dataset analysis.\nRelated Controls:  SC-12, SC-13. h\n-| (7) DEIDENTIFICATION  VALIDATED ALGORITHMS AND SOFTWAREu\nliPerform de-identification using validated algorithms and software that is validated to c\niimplement the algorithms.  o\niDiscussion:  Algorithms that appear to remove personally identifiable information from a s\ndataset may in fact leave information that is personally identifiable or data that is re-v\niidentifiable. Software that is claimed to implement a validated algorithm may contain bugs la\nor implement a different algorithm. Software may de-identify one type of data, such as le\nintegers, but not de-identify another type of data, such as floating point numbers. For these r\nreasons, de-identification is performed using algorithms and software that are validated.\ncRelated Controls:  None.\n-| (8) DEIDENTIFICATION  MOTIVATED INTRUDERe\noPerform a motivated intruder test on the de-identified dataset to determine if the\n:identified data remains or if the de-identified data can be re-identified.\npDiscussion:  A motivated intruder test is a test in which an individual or group takes a data\n/release and specified resources and attempts to re-identify one or more individuals in the /\no computational de-identified dataset. Such tests specify the amount of inside knowledge,i.\nrresources, financial resources, data, and skills that intruders possess to conduct the tests. A\nmotivated intruder test can determine if the de-identification is insufficient. It can also be a\nuseful diagnostic tool to assess if de-identification is likely to be sufficient. However, the test\nalone cannot prove that de-identification is sufficient. 8\nIRelated Controls:  None. S\nReferences:  [OMB A-130], [SP 800-188]."
}