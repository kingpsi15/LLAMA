{
  "subheading": "SA-11 DEVELOPER TESTING AND EVALUATION",
  "start_text": "SA-11 DEVELOPER TESTING AND EVALUATION\nControl:  R",
  "content": "SA-11 DEVELOPER TESTING AND EVALUATION\nControl:  Require the developer of the system, system component, or system service, at all post-\ndesign stages of the system development life cycle, to:\na.Develop and implement a plan for ongoing security and privacy control assessments;\nSelection (one or more): unit; integration; system; regressionb.Perform [] testing/evaluation  lic\nAssignment: organization-defined frequencyAssignment: organization-defined depth [] at [\nand coveragen];\nac.Produce evidence of the execution of the assessment plan and the results of the testing and\nevaluation; i\nled.Implement a verifiable flaw remediation process; and\ne.Correct flaws identified during testing and evaluation.\nDiscussion:  Developmental testing and evaluation confirms that the required controls are h\nrimplemented correctly, operating as intended, enforcing the desired security and privacy\npolicies, and meeting established security and privacy requirements. Security properties of\nsystems and the privacy of individuals may be affected by the interconnection of system m\ncomponents or changes to those components. The interconnections or changes\u2014including h\npupgrading or replacing applications, operating systems, and firmware\u2014may adversely affect\n/previously implemented controls. Ongoing assessment during development allows for additional /\ntypes of testing and evaluation that developers can conduct to reduce or eliminate potential i.\nrflaws. Testing custom software applications may require approaches such as manual code\nreview, security architecture review, and penetration testing, as well as and static analysis,\ndynamic analysis, binary analysis, or a hybrid of the three analysis approaches.\n/Developers can use the analysis approaches, along with security instrumentation and fuzzing, in a\nSvariety of tools and in source code reviews. The security and privacy assessment plans include\n.the specific activities that developers plan to carry out, including the types of analyses, testing, S\nevaluation, and reviews of software and firmware components; the degree of rigor to be applied; .\nthe frequency of the ongoing testing and evaluation; and the types of artifacts produced during 0\nthose processes. The depth of testing and evaluation refers to the rigor and level of detail 3\nassociated with the assessment process. The coverage of testing and evaluation refers to the\nscope (i.e., number and type) of the artifacts included in the assessment process. Contracts\nspecify the acceptance criteria for security and privacy assessment plans, flaw remediation\nprocesses, and the evidence that the plans and processes have been diligently applied. Methods\nfor reviewing and protecting assessment plans, evidence, and documentation are commensurate\nwith the security category or classification level of the system. Contracts may specify protection\nrequirements for documentation.\n. Related Controls:  CA-2, CA-7, CM-4, SA-3, SA-4, SA-5, SA-8, SA-15, SA-17, SI-2, SR-5, SR-6, SR-7\nControl Enhancements:\nCHAPTER THREE   PAGE 276\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\n| (1) DEVELOPER TESTING AND EVALUATION  STATIC CODE ANALYSIS\nRequire the developer of the system, system component, or system service to employ\nstatic code analysis tools to identify common flaws and document the results of the\nanalysis.\nDiscussion:  Static code analysis provides a technology and methodology for security reviews\nand includes checking for weaknesses in the code as well as for the incorporation of libraries\nor other included code with known vulnerabilities or that are out-of-date and not supported.\nStatic code analysis can be used to identify vulnerabilities and enforce secure coding\npractices. It is most effective when used early in the development process, when each code\nchange can automatically be scanned for potential weaknesses. Static code analysis can\nprovide clear remediation guidance and identify defects for developers to fix. Evidence of\nthe correct implementation of static analysis can include aggregate defect density for critical\nTdefect types, evidence that defects were inspected by developers or security professionals,\nisand evidence that defects were remediated. A high density of ignored findings, commonly\nureferred to as false positives, indicates a potential problem with the analysis process or the\nlianalysis tool. In such cases, organizations weigh the validity of the evidence against evidence c\ntfrom other sources. i\nRelated Controls:  None. is\n| a(2) DEVELOPER TESTING AND EVALUATION  THREAT MODELING AND VULNERABILITY ANALYSES\nbRequire the developer of the system, system component, or system service to perform\nthreat modeling and vulnerability analyses during development and the subsequent f\netesting and evaluation of the system, component, or service that:\nAssignment: organization-defined (a)Uses the following contextual information: [ c\nainformation concerning impact, environment of operations, known or assumed\nethreats, and acceptable risk levels];\nAssignment: organization-defined tools (b)Employs the following tools and methods: [  m\nand methods ];\nAssignment: (c)Conducts the modeling and analyses at the following level of rigor: [ s\n/organization-defined breadth and depth of modeling and analyses]; and d\ni.Assignment: (d)Produces evidence that meets the following acceptance criteria: [ o\norganization-defined acceptance criteria]. /\n.Discussion:  Systems, system components, and system services may deviate significantly\n2from the functional and design specifications created during the requirements and design\nstages of the system development life cycle. Therefore, updates to threat modeling and N\nvulnerability analyses of those systems, system components, and system services during\nSdevelopment and prior to delivery are critical to the effective operation of those systems,\n.components, and services. Threat modeling and vulnerability analyses at this stage of the 8\n0system development life cycle ensure that design and implementation changes have been\n3accounted for and that vulnerabilities created because of those changes have been reviewed\nand mitigated.\nRelated controls: PM-15, RA-3, RA-5.\n|(3) DEVELOPER TESTING AND EVALUATION  INDEPENDENT VERIFICATION OF ASSESSMENT PLANS AND\nEVIDENCE\nAssignment: organization-defined (a)Require an independent agent satisfying [\nindependence criteria] to verify the correct implementation of the developer security\nand privacy assessment plans and the evidence produced during testing and\nevaluation; and\nCHAPTER THREE   PAGE 277\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\n(b)Verify that the independent agent is provided with sufficient information to complete\nthe verification process or granted the authority to obtain such information.\nDiscussion:  Independent agents have the qualifications\u2014including the expertise, skills,\ntraining, certifications, and experience\u2014to verify the correct implementation of developer\nsecurity and privacy assessment plans.\nRelated Controls:  AT-3, RA-5.\n| (4) DEVELOPER TESTING AND EVALUATION  MANUAL CODE REVIEWS\nRequire the developer of the system, system component, or system service to perform a\nAssignment: organization-defined specific codemanual code review of [] using the\nAssignment: organization-defined following processes, procedures, and/or techniques: [\nprocesses, procedures, and/or techniques].\nTDiscussion:  Manual code reviews are usually reserved for the critical software and firmware\nicomponents of systems. Manual code reviews are effective at identifying weaknesses that s\nurequire knowledge of the application\u2019s requirements or context that, in most cases, is\nliunavailable to automated analytic tools and techniques, such as static and dynamic analysis. c\ntThe benefits of manual code review include the ability to verify access control matrices i\nagainst application controls and review detailed aspects of cryptographic implementations\nand controls. a\niRelated Controls:  None. la\n| (5) DEVELOPER TESTING AND EVALUATION  PENETRATION TESTING\neRequire the developer of the system, system component, or system service to perform\nfpenetration testing:\naAssignment: organization-defined breadth and depth (a)At the following level of rigor: [\neof testing]; and\nAssignment: organization-defined constraints(b)Under the following constraints: [].   m\nhDiscussion:  Penetration testing is an assessment methodology in which assessors, using all\navailable information technology product or system documentation and working under\n/specific constraints, attempt to circumvent the implemented security and privacy features of\ninformation technology products and systems. Useful information for assessors who conduct i.\npenetration testing includes product and system design specifications, source code, and g\nadministrator and operator manuals. Penetration testing can include white-box, gray-box, or 0\nblack-box testing with analyses performed by skilled professionals who simulate adversary 0\n8actions. The objective of penetration testing is to discover vulnerabilities in systems, system\ncomponents, and services that result from implementation errors, configuration faults, or I\nother operational weaknesses or deficiencies. Penetration tests can be performed in\nPconjunction with automated and manual code reviews to provide a greater level of analysis\nWhen user session information and other personally than would ordinarily be possible.0\nidentifiable information is captured or recorded during penetration testing, such information 5\nris handled appropriately to protect privacy. 5\n, Related Controls:  CA-8PM-14, PM-25, PT-2, SA-3, SI-2, SI-6.\n| (6) DEVELOPER TESTING AND EVALUATION  ATTACK SURFACE REVIEWS\nRequire the developer of the system, system component, or system service to perform\nattack surface reviews.\nDiscussion:  Attack surfaces of systems and system components are exposed areas that\nmake those systems more vulnerable to attacks. Attack surfaces include any accessible areas\nwhere weaknesses or deficiencies in the hardware, software, and firmware components\nprovide opportunities for adversaries to exploit vulnerabilities. Attack surface reviews\nensure that developers analyze the design and implementation changes to systems and\nCHAPTER THREE   PAGE 278\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nmitigate attack vectors generated as a result of the changes. The correction of identified\nflaws includes deprecation of unsafe functions.\n. Related Controls:  SA-15\n| (7) DEVELOPER TESTING AND EVALUATION  VERIFY SCOPE OF TESTING AND EVALUATION\nRequire the developer of the system, system component, or system service to verify that\nthe scope of testing and evaluation provides complete coverage of the required controls at\nAssignment: organization-defined breadth and depth of the following level of rigor: [\ntesting and evaluation].\nDiscussion:  Verifying that testing and evaluation provides complete coverage of required\ncontrols can be accomplished by a variety of analytic techniques ranging from informal to\nformal. Each of these techniques provides an increasing level of assurance that corresponds\nto the degree of formality of the analysis. Rigorously demonstrating control coverage at the\nhighest levels of assurance can be achieved using formal modeling and analysis techniques, is\nincluding correlation between control implementation and corresponding test cases.\nliRelated Controls:  SA-15. c\n| (8) DEVELOPER TESTING AND EVALUATION  DYNAMIC CODE ANALYSISn\nRequire the developer of the system, system component, or system service to employ\nadynamic code analysis tools to identify common flaws and document the results of the\nanalysis. b\nDiscussion:  Dynamic code analysis provides runtime verification of software programs using f\netools capable of monitoring programs for memory corruption, user privilege issues, and\nfother potential security problems. Dynamic code analysis employs runtime tools to ensure\nthat security functionality performs in the way it was designed. A type of dynamic analysis, a\nknown as fuzz testing, induces program failures by deliberately introducing malformed or\nrandom data into software programs. Fuzz testing strategies are derived from the intended r\nuse of applications and the functional and design specifications for the applications. To\nunderstand the scope of dynamic code analysis and the assurance provided, organizations t\nsmay also consider conducting code coverage analysis (i.e., checking the degree to which the\ndcode has been tested using metrics such as percent of subroutines tested or percent of\ni.program statements called during execution of the test suite) and/or concordance analysis o\n(i.e., checking for words that are out of place in software code, such as non-English language\nwords or derogatory terms).\n2Related Controls:  None.\n|I (9) DEVELOPER TESTING AND EVALUATION  INTERACTIVE APPLICATION SECURITY TESTINGS\nRequire the developer of the system, system component, or system service to employ S\ninteractive application security testing tools to identify flaws and document the results. .\nDiscussion: Interactive (also known as instrumentation-based) application security testing is\n3a method of detecting vulnerabilities by observing applications as they run during testing.\nThe use of instrumentation relies on direct measurements of the actual running applications\nand uses access to the code, user interaction, libraries, frameworks, backend connections,\nand configurations to directly measure control effectiveness. When combined with analysis\ntechniques, interactive application security testing can identify a broad range of potential\nvulnerabilities and confirm control effectiveness. Instrumentation-based testing works in\nreal time and can be used continuously throughout the system development life cycle.\nRelated Controls:  None.\nReferences:  [ISO 15408-3], [SP 800-30], [SP 800-53A], [SP 800-154], [SP 800-160-1].\nCHAPTER THREE   PAGE 279\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________"
}