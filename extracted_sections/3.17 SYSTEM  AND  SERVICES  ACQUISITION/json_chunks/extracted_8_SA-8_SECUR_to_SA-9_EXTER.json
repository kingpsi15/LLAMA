{
  "subheading": "SA-8 SECURITY AND PRIVACY ENGINEERING PRINCIPLES",
  "start_text": "SA-8 SECURITY AND PRIVACY ENGINEERING PRINCIPLES b",
  "content": "SA-8 SECURITY AND PRIVACY ENGINEERING PRINCIPLES b\nControl:  Apply the following systems security and privacy engineering principles in the t i\nnspecification, design, development, implementation, and modification of the system and system\nAssignment: organization-defined systems security and privacy engineering components: [\nprinciplesa].\nDiscussion:  Systems security and privacy engineering principles are closely related to and le\nfimplemented throughout the system development life cycle (see SA-3). Organizations can apply r\nsystems security and privacy engineering principles to new systems under development or to\nsystems undergoing upgrades. For existing systems, organizations apply systems security and c\naprivacy engineering principles to system upgrades and modifications to the extent feasible, given\nethe current state of hardware, software, and firmware components within those systems.\nmThe application of systems security and privacy engineering principles helps organizations\nhdevelop trustworthy, secure, and resilient systems and reduces the susceptibility to disruptions,\nhazards, threats, and the creation of privacy problems for individuals. Examples of system\nsecurity engineering principles include: developing layered protections; establishing security and /\nprivacy policies, architecture, and controls as the foundation for design and development; i.\nincorporating security and privacy requirements into the system development life cycle; g\ndelineating physical and logical security boundaries; ensuring that developers are trained on how 0\nto build secure software; tailoring controls to meet organizational needs; and performing threat 0\n8modeling to identify use cases, threat agents, attack vectors and patterns, design patterns, and\ncompensating controls needed to mitigate risk. I\nSOrganizations that apply systems security and privacy engineering concepts and principles can\n.facilitate the development of trustworthy, secure systems, system components, and system 8\n0services; reduce risk to acceptable levels; and make informed risk management decisions. System\n3security engineering principles can also be used to protect against certain supply chain risks,\nincluding incorporating tamper-resistant hardware into a design.\nSC-Related Controls:  PL-8, PM-7, RA-2, RA-3, RA-9, SA-3, SA-4, SA-15, SA-17, SA-20, SC-2, SC-3,\n32, SC-39, SR-2, SR-3, SR-4, SR-5.\nControl Enhancements:\n|(1) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  CLEAR ABSTRACTIONS\nImplement the security design principle of clear abstractions.\nDiscussion:  The principle of clear abstractions states that a system has simple, well-defined\ninterfaces and functions that provide a consistent and intuitive view of the data and how the\ndata is managed. The clarity, simplicity, necessity, and sufficiency of the system interfaces\u2014\nCHAPTER THREE   PAGE 257\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\ncombined with a precise definition of their functional behavior\u2014promotes ease of analysis,\ninspection, and testing as well as the correct and secure use of the system. The clarity of an\nabstraction is subjective. Examples that reflect the application of this principle include\navoidance of redundant, unused interfaces; information hiding; and avoidance of semantic\noverloading of interfaces or their parameters. Information hiding (i.e., representation-\nindependent programming), is a design discipline used to ensure that the internal\nrepresentation of information in one system component is not visible to another system\ncomponent, such that the published abstraction is component invoking or calling the first\nnot influenced by how the data may be managed internally.\nRelated Controls:  None.\n|(2) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  LEAST COMMON MECHANISM\nAssignment: Implement the security design principle of least common mechanism in [\nhorganization-defined systems or system components].\nDiscussion:  The principle of least common mechanism states that the amount of mechanism\ncommon to more than one user and depended on by all users is minimized [POPEK74]. lic\nMechanism minimization implies that different components of a system refrain from using t\nnthe same mechanism to access a system resource. Every shared mechanism (especially a\nmechanism involving shared variables) represents a potential information path between\nusers and is designed with care to ensure that it does not unintentionally compromise a\nSALTZER75]. Implementing the principle of least common mechanism helps to security [\nreduce the adverse consequences of sharing the system state among different programs. A\nesingle program that corrupts a shared state (including shared variables) has the potential to\nocorrupt other programs that are dependent on the state. The principle of least common\nmechanism also supports the principle of simplicity of design and addresses the issue of h\nrLAMPSON73]. covert storage channels [g\nfRelated Controls:  None. r\n: | (3) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  MODULARITY AND LAYERING\nAssignment: Implement the security design principles of modularity and layering in [\n/organization-defined systems or system components]. d\ni.Discussion:  The principles of modularity and layering are fundamental across system o\nengineering disciplines. Modularity and layering derived from functional decomposition are\neffective in managing system complexity by making it possible to comprehend the structure\nof the system. Modular decomposition, or refinement in system design, is challenging and\nresists general statements of principle. Modularity serves to isolate functions and related /\nSdata structures into well-defined logical units. Layering allows the relationships of these\n.units to be better understood so that dependencies are clear and undesired complexity can S\nbe avoided. The security design principle of modularity extends functional modularity to .\ninclude considerations based on trust, trustworthiness, privilege, and security policy. 0\nSecurity-informed modular decomposition includes the allocation of policies to systems in a\n5network, separation of system applications into processes with distinct address spaces,\nallocation of system policies to layers, and separation of processes into subjects with distinct\nprivileges based on hardware-supported privilege domains.\nRelated Controls:  SC-2, SC-3.\n|(4) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  PARTIALLY ORDERED DEPENDENCIES\nAssignment: Implement the security design principle of partially ordered dependencies in [\norganization-defined systems or system components].\nDiscussion:  The principle of partially ordered dependencies states that the synchronization,\ncalling, and other dependencies in the system are partially ordered. A fundamental concept\nin system design is layering, whereby the system is organized into well-defined, functionally\nCHAPTER THREE   PAGE 258\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nrelated modules or components. The layers are linearly ordered with respect to inter-layer\ndependencies, such that higher layers are dependent on lower layers. While providing\nfunctionality to higher layers, some layers can be self-contained and not dependent on lower\nlayers. While a partial ordering of all functions in a given system may not be possible, if\ncircular dependencies are constrained to occur within layers, the inherent problems of\ncircularity can be more easily managed. Partially ordered dependencies and system layering\ncontribute significantly to the simplicity and coherency of the system design. Partially\nordered dependencies also facilitate system testing and analysis.\nRelated Controls:  None.\n|(5) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  EFFICIENTLY MEDIATED ACCESS\nAssignment: Implement the security design principle of efficiently mediated access in [\norganization-defined systems or system components].\nDiscussion:  The principle of efficiently mediated access states that policy enforcement is\nmechanisms utilize the least common mechanism available while satisfying stakeholder\nexpressed constraints. The mediation of access to system resources requirements withinlic\n(i.e., CPU, memory, devices, communication ports, services, infrastructure, data, and t\nninformation) is often the predominant security function of secure systems. It also enables\nthe realization of protections for the capability provided to stakeholders by the system.\nMediation of resource access can result in performance bottlenecks if the system is not a\ndesigned correctly. For example, by using hardware mechanisms, efficiently mediated access\ncan be achieved. Once access to a low-level resource such as memory has been obtained,\nehardware protection mechanisms can ensure that out-of-bounds access does not occur.\nRelated Controls:  AC-25. f\n|(6) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  MINIMIZED SHARING r\nAssignment: Implement the security design principle of minimized sharing in [f\nmorganization-defined systems or system components].\nDiscussion:  The principle of minimized sharing states that no computer resource is shared t\nsbetween system components (e.g., subjects, processes, functions) unless it is absolutely\ndnecessary to do so. Minimized sharing helps to simplify system design and implementation.\ni.In order to protect user-domain resources from arbitrary active entities, no resource is o\nshared unless that sharing has been explicitly requested and granted. The need for resource\nsharing can be motivated by the design principle of least common mechanism in the case of\ninternal entities or driven by stakeholder requirements. However, internal sharing is\ncarefully designed to avoid performance and covert storage and timing channel problems. /\nSSharing via common mechanism can increase the susceptibility of data and information to\n.unauthorized access, disclosure, use, or modification and can adversely affect the inherent S\ncapability provided by the system. To minimize sharing induced by common mechanisms, .\nsuch mechanisms can be designed to be reentrant or virtualized to preserve separation. 0\nMoreover, the use of global data to share information is carefully scrutinized. The lack of\n5encapsulation may obfuscate relationships among the sharing entities.\nRelated Controls:  SC-31.\n|(7) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  REDUCED COMPLEXITY\nAssignment: Implement the security design principle of reduced complexity in [\norganization-defined systems or system components].\nDiscussion:  The principle of reduced complexity states that the system design is as simple\nand small as possible. A small and simple design is more understandable, more analyzable,\nand less prone to error. The reduced complexity principle applies to any aspect of a system,\nbut it has particular importance for security due to the various analyses performed to obtain\nevidence about the emergent security property of the system. For such analyses to be\nCHAPTER THREE   PAGE 259\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nsuccessful, a small and simple design is essential. Application of the principle of reduced\ncomplexity contributes to the ability of system developers to understand the correctness\nand completeness of system security functions. It also facilitates the identification of\npotential vulnerabilities. The corollary of reduced complexity states that the simplicity of the\nsystem is directly related to the number of vulnerabilities it will contain; that is, simpler\nsystems contain fewer vulnerabilities. An benefit of reduced complexity is that it is easier to\nunderstand whether the intended security policy has been captured in the system design\nand that fewer vulnerabilities are likely to be introduced during engineering development.\nAn additional benefit is that any such conclusion about correctness, completeness, and the\nexistence of vulnerabilities can be reached with a higher degree of assurance in contrast to\nconclusions reached in situations where the system design is inherently more complex.\nTransitioning from older technologies to newer technologies (e.g., transitioning from IPv4 to\nIPv6) may require implementing the older and newer technologies simultaneously during the\ntransition period. This may result in a temporary increase in system complexity during the h\ntransition. p\nRelated Controls:  None. lic\ni |(8)o SECURITY AND PRIVACY ENGINEERING PRINCIPLES  SECURE EVOLVABILITY\nisAssignment: Implement the security design principle of secure evolvability in [\nvorganization-defined systems or system components].\nDiscussion:  The principle of secure evolvability states that a system is developed to facilitate\nthe maintenance of its security properties when there are changes to the system\u2019s structure,\neinterfaces, interconnections (i.e., system architecture), functionality, or configuration (i.e.,\nosecurity policy enforcement). Changes include a new, enhanced, or upgraded system\ncapability; maintenance and sustainment activities; and reconfiguration. Although it is not h\nrpossible to plan for every aspect of system evolution, system upgrades and changes can be g\nchanges in the anticipated by analyses of mission or business strategic direction, anticipatedf\nthreat environment, and anticipated maintenance and sustainment needs. It is unrealistic to m\nexpect that complex systems remain secure in contexts not envisioned during development, h\npwhether such contexts are related to the operational environment or to usage. A system\n/may be secure in some new contexts, but there is no guarantee that its emergent behavior /\nwill always be secure. It is easier to build trustworthiness into a system from the outset, and i.\nrit follows that the sustainment of system trustworthiness requires planning for change as g\nopposed to adapting in an ad hoc or non-methodical manner. The benefits of this principle 0\ninclude reduced vendor life cycle costs, reduced cost of ownership, improved system 0\n8security, more effective management of security risk, and less risk uncertainty.\nIRelated Controls:  CM-3. S\n|(9) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  TRUSTED COMPONENTS P\n0Assignment: Implement the security design principle of trusted components in [\norganization-defined systems or system components]. 5\n5Discussion:  The principle of trusted components states that a component is trustworthy to\nat least a level commensurate with the security dependencies it supports (i.e., how much it\nis trusted to perform its security functions by other components). This principle enables the\ncomposition of components such that trustworthiness is not inadvertently diminished and\nthe trust is not consequently misplaced. Ultimately, this principle demands some metric by\nwhich the trust in a component and the trustworthiness of a component can be measured\non the same abstract scale. The principle of trusted components is particularly relevant\nwhen considering systems and components in which there are complex chains of trust\ndependencies. A trust dependency is also referred to as a trust relationship and there may\nbe chains of trust relationships.\nCHAPTER THREE   PAGE 260\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nThe principle of trusted components also applies to a compound component that consists of\nsubcomponents (e.g., a subsystem), which may have varying levels of trustworthiness. The\nconservative assumption is that the trustworthiness of a compound component is that of its\nleast trustworthy subcomponent. It may be possible to provide a security engineering\nrationale that the trustworthiness of a particular compound component is greater than the\nconservative assumption. However, any such rationale reflects logical reasoning based on a\nclear statement of the trustworthiness objectives as well as relevant and credible evidence.\nThe trustworthiness of a compound component is not the same as increased application of\ndefense-in-depth layering within the component or a replication of components. Defense-in-\ndepth techniques do not increase the trustworthiness of the whole above that of the least\ntrustworthy component.\nRelated Controls:  None.\nT |(10) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  HIERARCHICAL TRUST h\nAssignment: organization-Implement the security design principle of hierarchical trust in [p\nbdefined systems or system components].\nDiscussion:  The principle of hierarchical trust for components builds on the principle of t\nntrusted components and states that the security dependencies in a system will form a partial\nordering if they preserve the principle of trusted components. The partial ordering provides\nthe basis for trustworthiness reasoning or an assurance case (assurance argument) when a\ncomposing a secure system from heterogeneously trustworthy components. To analyze a\nsystem composed of heterogeneously trustworthy components for its trustworthiness, it is\neessential to eliminate circular dependencies with regard to the trustworthiness. If a more\notrustworthy component located in a lower layer of the system were to depend on a less\ntrustworthy component in a higher layer, this would, in effect, put the components in the h\nrsame \u201cless trustworthy\u201d equivalence class per the principle of trusted components. Trust g\nrelationships, or chains of trust, can have various manifestations. For example, the root f\ncertificate of a certificate hierarchy is the most trusted node in the hierarchy, whereas the m\nleaves in the hierarchy may be the least trustworthy nodes. Another example occurs in a h\nplayered high-assurance system where the security kernel (including the hardware base),\n/which is located at the lowest layer of the system, is the most trustworthy component. The /\nprinciple of hierarchical trust, however, does not prohibit the use of overly trustworthy i.\nrcomponents. There may be cases in a system of low trustworthiness where it is reasonable g\nto employ a highly trustworthy component rather than one that is less trustworthy (e.g., due 0\n6 highly to availability or other cost-benefit driver). For such a case, any dependency of the0\n8trustworthy component upon a less trustworthy component does not degrade the\ntrustworthiness of the resulting low-trust system. I\nRelated Controls:  None..\n8 |(11) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  INVERSE MODIFICATION THRESHOLD\nAssignment: Implement the security design principle of inverse modification threshold in [5\nrorganization-defined systems or system components]. 5\nDiscussion:  The principle of inverse modification threshold builds on the principle of trusted\ncomponents and the principle of hierarchical trust and states that the degree of protection\nprovided to a component is commensurate with its trustworthiness. As the trust placed in a\ncomponent increases, the protection against unauthorized modification of the component\nalso increases to the same degree. Protection from unauthorized modification can come in\nthe form of the component\u2019s own self-protection and innate trustworthiness, or it can come\nfrom the protections afforded to the component from other elements or attributes of the\nsecurity architecture (to include protections in the environment of operation).\nRelated Controls:  None.\nCHAPTER THREE   PAGE 261\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\n|(12) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  HIERARCHICAL PROTECTION\nAssignment: Implement the security design principle of hierarchical protection in [\norganization-defined systems or system components].\nDiscussion:  The principle of hierarchical protection states that a component need not be\nprotected from more trustworthy components. In the degenerate case of the most trusted\ncomponent, it protects itself from all other components. For example, if an operating system\nkernel is deemed the most trustworthy component in a system, then it protects itself from\nall untrusted applications it supports, but the applications, conversely, do not need to\nprotect themselves from the kernel. The trustworthiness of users is a consideration for\napplying the principle of hierarchical protection. A trusted system need not protect itself\nfrom an equally trustworthy user, reflecting use of untrusted systems in \u201csystem high\u201d\nenvironments where users are highly trustworthy and where other protections are put in\nTplace to bound and protect the \u201csystem high\u201d execution environment.\nRelated Controls:  None.\n|l(13) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  MINIMIZED SECURITY ELEMENTS ic\nAssignment: iImplement the security design principle of minimized security elements in [o\norganization-defined systems or system components ].\nDiscussion:  The principle of minimized security elements states that the system does not v\nihave extraneous trusted components. The principle of minimized security elements has two la\naspects: the overall cost of security analysis and the complexity of security analysis. Trusted le\ncomponents are generally costlier to construct and implement, owing to the increased rigor r\nof development processes. Trusted components require greater security analysis to qualify\ntheir trustworthiness. Thus, to reduce the cost and decrease the complexity of the security c\naanalysis, a system contains as few trustworthy components as possible. The analysis of the\neinteraction of trusted components with other components of the system is one of the most\nimportant aspects of system security verification. If the interactions between components o\nare unnecessarily complex, the security of the system will also be more difficult to ascertain :\ntthan one whose internal trust relationships are simple and elegantly constructed. In general, t\nfewer trusted components result in fewer internal trust relationships and a simpler system. :\nRelated Controls:  None.\n|(14) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  LEAST PRIVILEGE /\n.Assignment: organization-Implement the security design principle of least privilege in [6\n2defined systems or system components].\nDiscussion:  The principle of least privilege states that each system component is allocated\nTsufficient privileges to accomplish its specified functions but no more. Applying the principle\nof least privilege limits the scope of the component\u2019s actions, which has two desirable P\neffects: the security impact of a failure, corruption, or misuse of the component will have a 0\n-minimized security impact, and the security analysis of the component will be simplified.\nLeast privilege is a pervasive principle that is reflected in all aspects of the secure system r\ndesign. Interfaces used to invoke component capability are available to only certain subsets\nof the user population, and component design supports a sufficiently fine granularity of\nprivilege decomposition. For example, in the case of an audit mechanism, there may be an\ninterface for the audit manager, who configures the audit settings; an interface for the audit\nfinally, yet another operator, who ensures that audit data is safely collected and stored; and,\ninterface for the audit reviewer, who only has need to view the audit data that has been\ncollected but no need to perform operations on that data.\nIn addition to its manifestations at the system interface, least privilege can be used as a\nguiding principle for the internal structure of the system itself. One aspect of internal least\nprivilege is to construct modules so that only the elements encapsulated by the module are\nCHAPTER THREE   PAGE 262\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\ndirectly operated on by the functions within the module. Elements external to a module that\nmay be affected by the module\u2019s operation are indirectly accessed through interaction (e.g.,\nvia a function call) with the module that contains those elements. Another aspect of internal\nleast privilege is that the scope of a given module or component includes only those system\nelements that are necessary for its functionality and that the access modes for the elements\n(e.g., read, write) are minimal.\n.Related Controls:  AC-6, CM-7\n|(15) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  PREDICATE PERMISSION\nAssignment: Implement the security design principle of predicate permission in [\norganization-defined systems or system components].\nDiscussion:  The principle of predicate permission states that system designers consider\nrequiring multiple authorized entities to provide consent before a highly critical operation or\nSALTZER75] access to highly sensitive data, information, or resources is allowed to proceed. [is\noriginally named predicate permission the separation of privilege. It is also equivalent to\nseparation of duty. The division of privilege among multiple parties decreases the likelihood lic\nof abuse and provides the safeguard that no single accident, deception, or breach of trust is t\nnsufficient to enable an unrecoverable action that can lead to significantly damaging effects.\nThe design options for such a mechanism may require simultaneous action (e.g., the firing of\na nuclear weapon requires two different authorized individuals to give the correct command a\nwithin a small time window) or a sequence of operations where each successive action is\nenabled by some prior action, but no single individual is able to enable more than one\neaction.\nRelated Controls:  AC-5. f\n|-(16) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  SELFRELIANT TRUSTWORTHINESS r\nAssignment: Implement the security design principle of self-reliant trustworthiness in [f\nmorganization-defined systems or system components].\nDiscussion:  The principle of self-reliant trustworthiness states that systems minimize their t\nsreliance on other systems for their own trustworthiness. A system is trustworthy by default,\ndand any connection to an external entity is used to supplement its function. If a system were\ni.required to maintain a connection with another external entity in order to maintain its o\ntrustworthiness, then that system would be vulnerable to malicious and non-malicious\nthreats that could result in the loss or degradation of that connection. The benefit of the\nprinciple of self-reliant trustworthiness is that the isolation of a system will make it less\nvulnerable to attack. A corollary to this principle relates to the ability of the system (or /\nSsystem component) to operate in isolation and then resynchronize with other components\n.when it is rejoined with them. S\n.Related Controls:  None. 8\n- |5(17) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  SECURE DISTRIBUTED COMPOSITION\nAssignment: Implement the security design principle of secure distributed composition in [\norganization-defined systems or system components].\nDiscussion:  The principle of secure distributed composition states that the composition of\ndistributed components that enforce the same system security policy result in a system that\nenforces that policy at least as well as the individual components do. Many of the design\nprinciples for secure systems deal with how components can or should interact. The need to\ncreate or enable a capability from the composition of distributed components can magnify\nthe relevancy of these principles. In particular, the translation of security policy from a\nstand-alone to a distributed system or a system-of-systems can have unexpected or\nemergent results. Communication protocols and distributed data consistency mechanisms\nhelp to ensure consistent policy enforcement across a distributed system. To ensure a\nCHAPTER THREE   PAGE 263\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nsystem-wide level of assurance of correct policy enforcement, the security architecture of a\ndistributed composite system is thoroughly analyzed.\nRelated Controls:  None.\n|(18) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  TRUSTED COMMUNICATIONS CHANNELS\nImplement the security design principle of trusted communications channels in\nAssignment: organization-defined systems or system components[].\nDiscussion:  The principle of trusted communication channels states that when composing a\nsystem where there is a potential threat to communications between components (i.e., the\ninterconnections between components), each communication channel is trustworthy to a\nlevel commensurate with the security dependencies it supports (i.e., how much it is trusted\nby other components to perform its security functions). Trusted communication channels\nare achieved by a combination of restricting access to the communication channel (to ensure\nan acceptable match in the trustworthiness of the endpoints involved in the communication) is\nand employing end-to-end protections for the data transmitted over the communication\nchannel (to protect against interception and modification and to further increase the lic\nassurance of proper end-to-end communication). t\nRelated Controls:  SC-8, SC-12, SC-13.\nv|(19) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  CONTINUOUS PROTECTION\nAssignment: Implement the security design principle of continuous protection in [b\norganization-defined systems or system components].\neDiscussion:  The principle of continuous protection states that components and data used to\nfenforce the security policy have uninterrupted protection that is consistent with the security\npolicy and the security architecture assumptions. No assurances that the system can provide a\nthe confidentiality, integrity, availability, and privacy protections for its design capability can\nbe made if there are gaps in the protection. Any assurances about the ability to secure a r\ndelivered capability require that data and information are continuously protected. That is,\nthere are no periods during which data and information are left unprotected while under t\nscontrol of the system (i.e., during the creation, storage, processing, or communication of the\nddata and information, as well as during system initialization, execution, failure, interruption,\ni.and shutdown). Continuous protection requires adherence to the precepts of the reference o\nmonitor concept (i.e., every request is validated by the reference monitor; the reference\nmonitor is able to protect itself from tampering; and sufficient assurance of the correctness\nand completeness of the mechanism can be ascertained from analysis and testing) and the\nprinciple of secure failure and recovery (i.e., preservation of a secure state during error, /\nSfault, failure, and successful attack; preservation of a secure state during recovery to normal,\n.degraded, or alternative operational modes). S\n8Continuous protection also applies to systems designed to operate in varying configurations,\nincluding those that deliver full operational capability and degraded-mode configurations -\nthat deliver partial operational capability. The continuous protection principle requires that r\nchanges to the system security policies be traceable to the operational need that drives the\nconfiguration and be verifiable (i.e., it is possible to verify that the proposed changes will not\nput the system into an insecure state). Insufficient traceability and verification may lead to\ninconsistent states or protection discontinuities due to the complex or undecidable nature of\nthe problem. The use of pre-verified configuration definitions that reflect the new security\npolicy enables analysis to determine that a transition from old to new policies is essentially\natomic and that any residual effects from the old policy are guaranteed to not conflict with\nthe new policy. The ability to demonstrate continuous protection is rooted in the clear\narticulation of life cycle protection needs as stakeholder security requirements.\n. Related Controls:  AC-25\nCHAPTER THREE   PAGE 264\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\n|(20) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  SECURE METADATA MANAGEMENT\nAssignment: Implement the security design principle of secure metadata management in [\norganization-defined systems or system components].\nDiscussion:  The principle of secure metadata management states that metadata are \u201cfirst\nclass\u201d objects with respect to security policy when the policy requires either complete\nprotection of information or that the security subsystem be self-protecting. The principle of\nsecure metadata management is driven by the recognition that a system, subsystem, or\ncomponent cannot achieve self-protection unless it protects the data it relies on for correct\nexecution. Data is generally not interpreted by the system that stores it. It may have\nsemantic value (i.e., it comprises information) to users and programs that process the data.\nIn contrast, metadata is information about data, such as a file name or the date when the\nfile was created. Metadata is bound to the target data that it describes in a way that the\nTsystem can interpret, but it need not be stored inside of or proximate to its target data.\nisThere may be metadata whose target is itself metadata (e.g., the classification level or\nuimpact level of a file name), including self-referential metadata.\naThe apparent secondary nature of metadata can lead to neglect of its legitimate need for\nprotection, resulting in a violation of the security policy that includes the exfiltration of\nisinformation. A particular concern associated with insufficient protections for metadata is\nvassociated with multilevel secure (MLS) systems. MLS systems mediate access by a subject to\nlan object based on relative sensitivity levels. It follows that all subjects and objects in the a\nlscope of control of the MLS system are either directly labeled or indirectly attributed with e\nrsensitivity levels. The corollary of labeled metadata for MLS systems states that objects e\ncontaining metadata are labeled. As with protection needs assessments for data, attention is o\ncgiven to ensure that the confidentiality and integrity protections are individually assessed,\nspecified, and allocated to metadata, as would be done for mission, business, and system r\ndata.\nRelated Controls:  None.m\nt |-(21) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  SELFANALYSIS t\nAssignment: organization-/Implement the security design principle of self-analysis in [\nodefined systems or system components].\nDiscussion:  The principle of self-analysis states that a system component is able to assess its g\ninternal state and functionality to a limited extent at various stages of execution, and that 0\nthis self-analysis capability is commensurate with the level of trustworthiness invested in the 0\n8system. At the system level, self-analysis can be achieved through hierarchical assessments\nof trustworthiness established in a bottom-up fashion. In this approach, the lower-level I\ncomponents check for data integrity and correct functionality (to a limited extent) of higher-\nPlevel components. For example, trusted boot sequences involve a trusted lower-level\n0component that attests to the trustworthiness of the next higher-level components so that a\ntransitive chain of trust can be established. At the root, a component attests to itself, which 5\nrusually involves an axiomatic or environmentally enforced assumption about its integrity. 5\nResults of the self-analyses can be used to guard against externally induced errors, internal\nmalfunction, or transient errors. By following this principle, some simple malfunctions or\nerrors can be detected without allowing the effects of the error or malfunction to propagate\noutside of the component. Further, the self-test can be used to attest to the configuration of\nthe component, detecting any potential conflicts in configuration with respect to the\nexpected configuration.\nRelated Controls:  CA-7.\n|(22) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  ACCOUNTABILITY AND TRACEABILITY\nCHAPTER THREE   PAGE 265\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nAssignment: Implement the security design principle of accountability and traceability in [\norganization-defined systems or system components].\nDiscussion:  The principle of accountability and traceability states that it is possible to trace\nsecurity-relevant actions (i.e., subject-object interactions) to the entity on whose behalf the\naction is being taken. The principle of accountability and traceability requires a trustworthy\ninfrastructure that can record details about actions that affect system security (e.g., an audit\nsubsystem). To record the details about actions, the system is able to uniquely identify the\nentity on whose behalf the action is being carried out and also record the relevant sequence\nof actions that are carried out. The accountability policy also requires that audit trail itself be\nprotected from unauthorized access and modification. The principle of least privilege assists\nin tracing the actions to particular entities, as it increases the granularity of accountability.\nAssociating specific actions with system entities, and ultimately with users, and making the\naudit trail secure against unauthorized access and modifications provide non-repudiation\nbecause once an action is recorded, it is not possible to change the audit trail. Another\npimportant function that accountability and traceability serves is in the routine and forensic\nanalysis of events associated with the violation of security policy. Analysis of audit logs may lic\nprovide additional information that may be helpful in determining the path or component\nthat allowed the violation of the security policy and the actions of individuals associated with n\nthe violation of the security policy.\naRelated Controls:  AC-6,AU-2, AU-3, AU-6, AU-9, AU-10,AU-12,IA-2, IR-4.\nl|(23) eSECURITY AND PRIVACY ENGINEERING PRINCIPLES  SECURE DEFAULTS\neAssignment: organization-Implement the security design principle of secure defaults in [\nodefined systems or system components].\nDiscussion:  The principle of secure defaults states that the default configuration of a system\ng(including its constituent subsystems, components, and mechanisms) reflects a restrictive\nfand conservative enforcement of security policy. The principle of secure defaults applies to r\nthe initial (i.e., default) configuration of a system as well as to the security engineering and\ndesign of access control and other security functions that follow a \u201cdeny unless explicitly\nauthorized\u201d strategy. The initial configuration aspect of this principle requires that any \u201cas s\nshipped\u201d configuration of a system, subsystem, or system component does not aid in the d\ni.violation of the security policy and can prevent the system from operating in the default\ngconfiguration for those cases where the security policy itself requires configuration by the\n0operational user.\nRestrictive defaults mean that the system will operate \u201cas-shipped\u201d with adequate self-\nNprotection and be able to prevent security breaches before the intended security policy and\nsystem configuration is established. In cases where the protection provided by the \u201cas-T\nshipped\u201d product is inadequate, stakeholders assess the risk of using it prior to establishing a\n8secure initial state. Adherence to the principle of secure defaults guarantees that a system is\nestablished in a secure state upon successfully completing initialization. In situations where -\nthe system fails to complete initialization, either it will perform a requested operation using\nsecure defaults or it will not perform the operation. Refer to the principles of continuous\nprotection and secure failure and recovery that parallel this principle to provide the ability to\ndetect and recover from failure.\nThe security engineering approach to this principle states that security mechanisms deny\nrequests unless the request is found to be well-formed and consistent with the security\npolicy. The insecure alternative is to allow a request unless it is shown to be inconsistent\nwith the policy. In a large system, the conditions that are satisfied to grant a request that is\ndenied by default are often far more compact and complete than those that would need to\nbe checked in order to deny a request that is granted by default.\n.Related Controls:  CM-2, CM-6, SA-4\nCHAPTER THREE   PAGE 266\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\n|(24) SECURITY AND PRIVACY ENGINEERING PRINCIPLES SECURE FAILURE AND RECOVERY\nAssignment: Implement the security design principle of secure failure and recovery in [\norganization-defined systems or system components].\nDiscussion:  The principle of secure failure and recovery states that neither a failure in a\nsystem function or mechanism nor any recovery action in response to failure leads to a\nviolation of security policy. The principle of secure failure and recovery parallels the principle\nof continuous protection to ensure that a system is capable of detecting (within limits) actual\nand impending failure at any stage of its operation (i.e., initialization, normal operation,\nshutdown, and maintenance) and to take appropriate steps to ensure that security policies\nare not violated. In addition, when specified, the system is capable of recovering from\nimpending or actual failure to resume normal, degraded, or alternative secure operations\nwhile ensuring that a secure state is maintained such that security policies are not violated.\nhFailure is a condition in which the behavior of a component deviates from its specified or\nexpected behavior for an explicitly documented input. Once a failed security function is p\nbdetected, the system may reconfigure itself to circumvent the failed component while\namaintaining security and provide all or part of the functionality of the original system, or it\nmay completely shut itself down to prevent any further violation of security policies. For this\nisto occur, the reconfiguration functions of the system are designed to ensure continuous\nvenforcement of security policy during the various phases of reconfiguration.\nbAnother technique that can be used to recover from failures is to perform a rollback to a\nsecure state (which may be the initial state) and then either shutdown or replace the service f\nor component that failed such that secure operations may resume. Failure of a component e\nmay or may not be detectable to the components using it. The principle of secure failure f\nindicates that components fail in a state that denies rather than grants access. For example,\nga nominally \u201catomic\u201d operation interrupted before completion does not violate security\nfpolicy and is designed to handle interruption events by employing higher-level atomicity and r\nrollback mechanisms (e.g., transactions). If a service is being used, its atomicity properties\nare well-documented and characterized so that the component availing itself of that service\ncan detect and handle interruption events appropriately. For example, a system is designed s\nto gracefully respond to disconnection and support resynchronization and data consistency d\ni.after disconnection.\n1Failure protection strategies that employ replication of policy enforcement mechanisms,\n6sometimes called defense in depth, can allow the system to continue in a secure state even\nwhen one mechanism has failed to protect the system. If the mechanisms are similar,\nNhowever, the additional protection may be illusory, as the adversary can simply attack in\nseries. Similarly, in a networked system, breaking the security on one system or service may T\nenable an attacker to do the same on other similar replicated systems and services. By\n8employing multiple protection mechanisms whose features are significantly different, the\npossibility of attack replication or repetition can be reduced. Analyses are conducted to -\nweigh the costs and benefits of such redundancy techniques against increased resource\nusage and adverse effects on the overall system performance. Additional analyses are\nconducted as the complexity of these mechanisms increases, as could be the case for\ndynamic behaviors. Increased complexity generally reduces trustworthiness. When a\nresource cannot be continuously protected, it is critical to detect and repair any security\nbreaches before the resource is once again used in a secure context.\n. Related Controls:  CP-10, CP-12, SC-7, SC-8, SC-24, SI-13\n|(25) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  ECONOMIC SECURITY\nAssignment: organization-Implement the security design principle of economic security in [\ndefined systems or system components].\nCHAPTER THREE   PAGE 267\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nDiscussion:  The principle of economic security states that security mechanisms are not\ncostlier than the potential damage that could occur from a security breach. This is the\nsecurity-relevant form of the cost-benefit analyses used in risk management. The cost\nassumptions of cost-benefit analysis prevent the system designer from incorporating\nsecurity mechanisms of greater strength than necessary, where strength of mechanism is\nproportional to cost. The principle of economic security also requires analysis of the benefits\nof assurance relative to the cost of that assurance in terms of the effort expended to obtain\nrelevant and credible evidence as well as the necessary analyses to assess and draw\ntrustworthiness and risk conclusions from the evidence.\nRelated Controls:  RA-3.\n|(26) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  PERFORMANCE SECURITY\nAssignment: Implement the security design principle of performance security in [\nhorganization-defined systems or system components].\nDiscussion:  The principle of performance security states that security mechanisms are\nconstructed so that they do not degrade system performance unnecessarily. Stakeholder lic\nand system design requirements for performance and security are precisely articulated and t\nnprioritized. For the system implementation to meet its design requirements and be found\nacceptable to stakeholders (i.e., validation against stakeholder requirements), the designers\nadhere to the specified constraints that capability performance needs place on protection a\nla computationally intensive security services (e.g., cryptography) needs. The overall impact of\nare assessed and demonstrated to pose no significant impact to higher-priority performance\neconsiderations or are deemed to provide an acceptable trade-off of performance for\notrustworthy protection. The trade-off considerations include less computationally intensive\nsecurity services unless they are unavailable or insufficient. The insufficiency of a security h\nrservice is determined by functional capability and strength of mechanism. The strength of g\nmechanism is selected with respect to security requirements, performance-critical overhead f\nissues (e.g., cryptographic key management), and an assessment of the capability of the m\nthreat. h\nThe principle of performance security leads to the incorporation of features that help in the :\nenforcement of security policy but incur minimum overhead, such as low-level hardware\nomechanisms upon which higher-level services can be built. Such low-level mechanisms are\nusually very specific, have very limited functionality, and are optimized for performance. For /\nexample, once access rights to a portion of memory is granted, many systems use hardware .\nmechanisms to ensure that all further accesses involve the correct memory address and 2\n/access mode. Application of this principle reinforces the need to design security into the N\nsystem from the ground up and to incorporate simple mechanisms at the lower layers that\nScan be used as building blocks for higher-level mechanisms.\n8.Related Controls:  SC-12, SC-13, SI-2, SI-7\n5 |(27) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  HUMAN FACTORED SECURITY\nAssignment: Implement the security design principle of human factored security in [\norganization-defined systems or system components].\nDiscussion:  The principle of human factored security states that the user interface for\nsecurity functions and supporting services is intuitive, user-friendly, and provides feedback\nfor user actions that affect such policy and its enforcement. The mechanisms that enforce\nsecurity policy are not intrusive to the user and are designed not to degrade user efficiency.\nSecurity policy enforcement mechanisms also provide the user with meaningful, clear, and\nrelevant feedback and warnings when insecure choices are being made. Particular attention\nis given to interfaces through which personnel responsible for system administration and\noperation configure and set up the security policies. Ideally, these personnel are able to\nCHAPTER THREE   PAGE 268\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nunderstand the impact of their choices. Personnel with system administrative and\noperational responsibilities are able to configure systems before start-up and administer\nthem during runtime with confidence that their intent is correctly mapped to the system\u2019s\nmechanisms. Security services, functions, and mechanisms do not impede or unnecessarily\ncomplicate the intended use of the system. There is a trade-off between system usability\nand the strictness necessary for security policy enforcement. If security mechanisms are\nfrustrating or difficult to use, then users may disable them, avoid them, or use them in ways\ninconsistent with the security requirements and protection needs that the mechanisms were\ndesigned to satisfy.\nRelated Controls:  None.\n|(28) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  ACCEPTABLE SECURITY\nAssignment: Implement the security design principle of acceptable security in [\nhorganization-defined systems or system components].\nDiscussion:  The principle of acceptable security requires that the level of privacy and\nperformance that the system provides is consistent with the users\u2019 expectations. The lic\nperception of personal privacy may affect user behavior, morale, and effectiveness. Based t\nnon the organizational privacy policy and the system design, users should be able to restrict\ntheir actions to protect their privacy. When systems fail to provide intuitive interfaces or\nmeet privacy and performance expectations, users may either choose to completely avoid a\nthe system or use it in ways that may be inefficient or even insecure.\nRelated Controls:  None. f\n|(29) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  REPEATABLE AND DOCUMENTED PROCEDURESo\nhImplement the security design principle of repeatable and documented procedures in\nAssignment: organization-defined systems or system components[]. g\nDiscussion:  The principle of repeatable and documented procedures states that the r\ntechniques and methods employed to construct a system component permit the same\ncomponent to be completely and correctly reconstructed at a later time. Repeatable and t\nsdocumented procedures support the development of a component that is identical to the\ndcomponent created earlier, which may be in widespread use. In the case of other system\ni.artifacts (e.g., documentation and testing results), repeatability supports consistency and the o\nability to inspect the artifacts. Repeatable and documented procedures can be introduced at\nvarious stages within the system development life cycle and contribute to the ability to\nevaluate assurance claims for the system. Examples include systematic procedures for code\ndevelopment and review, procedures for the configuration management of development /\nStools and system artifacts, and procedures for system delivery.\nSRelated Controls:  CM-1, SA-1, SA-10, SA-11, SA-15, SA-17, SC-1, SI-1.\n0|(30) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  PROCEDURAL RIGOR\nAssignment: organization-Implement the security design principle of procedural rigor in [3\ndefined systems or system components].\nDiscussion:  The principle of procedural rigor states that the rigor of a system life cycle\nprocess is commensurate with its intended trustworthiness. Procedural rigor defines the\nscope, depth, and detail of the system life cycle procedures. Rigorous system life cycle\nprocedures contribute to the assurance that the system is correct and free of unintended\nfunctionality in several ways. First, the procedures impose checks and balances on the life\ncycle process such that the introduction of unspecified functionality is prevented.\nSecond, rigorous procedures applied to systems security engineering activities that produce\nspecifications and other system design documents contribute to the ability to understand\nCHAPTER THREE   PAGE 269\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nthe system as it has been built rather than trusting that the component, as implemented, is\nthe authoritative (and potentially misleading) specification.\nFinally, modifications to an existing system component are easier when there are detailed\nspecifications that describe its current design instead of studying source code or schematics\nto try to understand how it works. Procedural rigor helps ensure that security functional and\nassurance requirements have been satisfied, and it contributes to a better-informed basis\nfor the determination of trustworthiness and risk posture. Procedural rigor is commensurate\nwith the degree of assurance desired for the system. If the required trustworthiness of the\nsystem is low, a high level of procedural rigor may add unnecessary cost, whereas when high\ntrustworthiness is critical, the cost of high procedural rigor is merited.\nRelated Controls:  None.\n|(31) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  SECURE SYSTEM MODIFICATION\niAssignment: sImplement the security design principle of secure system modification in [\nuorganization-defined systems or system components].\nlicDiscussion:  The principle of secure system modification states that system modification\nimaintains system security with respect to the security requirements and risk tolerance of o\nstakeholders. Upgrades or modifications to systems can transform secure systems into is\nsystems that are not secure. The procedures for system modification ensure that if the\nisystem is to maintain its trustworthiness, the same rigor that was applied to its initial la\ndevelopment is applied to any system changes. Because modifications can affect the ability le\nfof the system to maintain its secure state, a careful security analysis of the modification is r\nneeded prior to its implementation and deployment. This principle parallels the principle of\nsecure evolvability.\nRelated Controls:  CM-3, CM-4. r\nf |(32) rSECURITY AND PRIVACY ENGINEERING PRINCIPLES  SUFFICIENT DOCUMENTATION\nAssignment: Implement the security design principle of sufficient documentation in [:\ntorganization-defined systems or system components]. t\nDiscussion:  The principle of sufficient documentation states that organizational personnel /\nowith responsibilities to interact with the system are provided with adequate documentation\nand other information such that the personnel contribute to rather than detract from r\n1system security. Despite attempts to comply with principles such as human factored security\n6and acceptable security, systems are inherently complex, and the design intent for the use of\n2 of security security mechanisms and the ramifications of the misuse or misconfiguration8\nmechanisms are not always intuitively obvious. Uninformed and insufficiently trained users\nTcan introduce vulnerabilities due to errors of omission and commission. The availability of\ndocumentation and training can help to ensure a knowledgeable cadre of personnel, all of P\n8whom have a critical role in the achievement of principles such as continuous protection.\nDocumentation is written clearly and supported by training that provides security awareness -\nand understanding of security-relevant responsibilities. r\nRelated Controls:  AT-2, AT-3, SA-5.\n|  (33) SECURITY AND PRIVACY ENGINEERING PRINCIPLES  MINIMIZATION\nAssignment: organization-defined Implement the privacy principle of minimization using [\nprocesses].\nDiscussion: The principle of minimization states that organizations should only process\npersonally identifiable information that is directly relevant and necessary to accomplish an\nauthorized purpose and should only maintain personally identifiable information for as long\nas is necessary to accomplish the purpose. Organizations have processes in place, consistent\nwith applicable laws and policies, to implement the principle of minimization.\nCHAPTER THREE   PAGE 270\nNISTSP800-53,R.5SPCISO                                                               EV                                                                                      ECURITY AND RIVACY ONTROLS FOR NFORMATION YSTEMS AND RGANIZATIONS\n_________________________________________________________________________________________________\nRelated Controls:  PE-8, PM-25, SC-42, SI-12.\nReferences:  [PRIVACT], [OMB A-130], [FIPS 199], [FIPS 200], [SP 800-37], [SP 800-53A], [SP 800-\n60-1], [SP 800-60-2], [SP 800-160-1], [IR 8062]."
}